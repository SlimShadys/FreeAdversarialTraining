{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Neural Networks__\n",
    "## Exam Project: Adversarial Training for Free!\n",
    "\n",
    "**Students**:\n",
    "- **Name**: *Gianmarco Scarano* | Matricola Code: *2047315*<br>\n",
    "- **Name**: *Giancarlo Tedesco* | Matricola Code: *2057231*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Colab compatibility\n",
    "Run this next cell only if you're using Google Colab!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library needed for this notebook\n",
    "!pip install -U tqdm --quiet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We set the global variable for Google Colab, so we can assign possible paths, etc. accordingly\n",
    "try:\n",
    "  import google.colab\n",
    "  RunningInCOLAB = True\n",
    "except:\n",
    "  RunningInCOLAB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependecies loaded\n",
      "===================================================\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "print('Dependecies loaded')\n",
    "print(\"===================================================\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if we have CUDA support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available: True\n",
      "GPU: NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "Total memory: 6.0 GB\n",
      "===================================================\n"
     ]
    }
   ],
   "source": [
    "if(torch.cuda.is_available()):\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('Cuda available: {}'.format(torch.cuda.is_available()))\n",
    "    print(\"GPU: \" + torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "    print(\"Total memory: {:.1f} GB\".format((float(torch.cuda.get_device_properties(0).total_memory / (1024 ** 3)))))\n",
    "    print(\"===================================================\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('Cuda not available, so using CPU. Please consider switching to a GPU runtime before running the notebook!')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the train dataset\n",
    "train_dataset = datasets.FashionMNIST(root ='./', train=True, download=True, transform=transform)\n",
    "\n",
    "# Download the test dataset\n",
    "test_dataset = datasets.FashionMNIST(root ='./', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create train and test data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition: DummyNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(DummyNet, self).__init__()\n",
    "\n",
    "        # First convolution\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1, device=device)\n",
    "        self.bn1 = nn.BatchNorm2d(32, device=device)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Second convolution\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1, device=device)\n",
    "        self.bn2 = nn.BatchNorm2d(64, device=device)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Third convolution\n",
    "        self.conv3 = nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1, device=device)\n",
    "        self.bn3 = nn.BatchNorm2d(32, device=device)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Activation functions\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "        # Flatten layer\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(288, 150, device=device) # 288 is the output shape of the Flatten() function applied after the 3rd convolutional block.\n",
    "        self.fc2 = nn.Linear(150, 50, device=device)\n",
    "        self.fc3 = nn.Linear(50, num_classes, device=device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.relu(self.bn1(self.conv1(x)))) # First convolution\n",
    "        x = self.pool2(self.relu(self.bn2(self.conv2(x)))) # Second convolution\n",
    "        x = self.pool3(self.relu(self.bn3(self.conv3(x)))) # Third convolution\n",
    "\n",
    "        x = self.flatten(x) # Flatten of the output of the 3rd convolutional block\n",
    "\n",
    "        x = self.relu(self.fc1(x))  # FC1\n",
    "        x = self.relu(self.fc2(x))  # FC2\n",
    "\n",
    "        x = self.fc3(x)             # Output layer\n",
    "        return self.softmax(x)      # Final activation function (SoftMax)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training phase"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define some variables for the training phase\n",
    "lr = 1e-3\n",
    "momentum = 0.9\n",
    "epochs = 100\n",
    "\n",
    "# Our model\n",
    "model = DummyNet(num_classes=10)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FreeAdversarial parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 2 # Usually it's a value m ≤ 10\n",
    "epochs = int(epochs / m)\n",
    "epsilon = 0.5\n",
    "delta = torch.zeros([32, 1, 28, 28], device=device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual training phase (Normal + FreeAdv)\n",
    "\n",
    "TODO:\n",
    "- Scalability for input sizes (W, H, D)\n",
    "- In the training loop, the accuracy is calculated for each iteration.\n",
    "  This is not correct, as the accuracy should be calculated for each epoch, after all training images are processed.\n",
    "- The validation accuracy is not being printed after each epoch.\n",
    "- The division of the images by std is not correct, before the forward pass, it should be images = (images - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch n.1 (Train): 100%|██████████| 1875/1875 [00:37<00:00, 49.66it/s]\n",
      "Epoch n.1 (Validation): 100%|██████████| 313/313 [00:03<00:00, 101.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001:\n",
      "\t- Training accuracy   : 0.5312\n",
      "\t- Training loss       : 1.8885\n",
      "\t- Validation accuracy : 0.3742\n",
      "\t- Validation loss : 2.0210\n",
      "=========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch n.2 (Train): 100%|██████████| 1875/1875 [00:37<00:00, 49.74it/s]\n",
      "Epoch n.2 (Validation): 100%|██████████| 313/313 [00:03<00:00, 100.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 002:\n",
      "\t- Training accuracy   : 0.4375\n",
      "\t- Training loss       : 1.9825\n",
      "\t- Validation accuracy : 0.4219\n",
      "\t- Validation loss : 1.9430\n",
      "=========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch n.3 (Train): 100%|██████████| 1875/1875 [00:37<00:00, 50.07it/s]\n",
      "Epoch n.3 (Validation): 100%|██████████| 313/313 [00:03<00:00, 100.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 003:\n",
      "\t- Training accuracy   : 0.3750\n",
      "\t- Training loss       : 2.0397\n",
      "\t- Validation accuracy : 0.3221\n",
      "\t- Validation loss : 1.9463\n",
      "=========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch n.4 (Train):  92%|█████████▏| 1728/1875 [00:34<00:02, 50.03it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 35\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[39m# Backward pass and optimization\u001b[39;00m\n\u001b[0;32m     34\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> 35\u001b[0m loss\u001b[39m.\u001b[39;49mbackward(retain_graph\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m) \u001b[39m# 7: gθ ← E(x,y)∈B[∇θ l(x + δ, y, θ)] + 9: θ ← θ − τgθ ----> Plus we go popolate the noise_batch.grad value\u001b[39;00m\n\u001b[0;32m     37\u001b[0m gadv \u001b[39m=\u001b[39m noise_batch\u001b[39m.\u001b[39mgrad \u001b[39m# 8: gadv ← ∇x l(x + δ, y, θ)] ---> We already computed this, we are just storing it in a variable\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[39m# Update the noise for the next iteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Gianmarco\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    487\u001b[0m     )\n\u001b[1;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    490\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Gianmarco\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\autograd\\__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "noise_batch = None\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(epochs): # 3: for epoch = 1 . . . Nep/m do\n",
    "\n",
    "    mean = torch.Tensor(np.array([0.1307])[:, np.newaxis, np.newaxis])\n",
    "    mean = mean.expand(1, 28, 28).cuda()\n",
    "    std = torch.Tensor(np.array([0.3081])[:, np.newaxis, np.newaxis])\n",
    "    std = std.expand(1, 28, 28).cuda()\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    for i, (images, labels) in enumerate(tqdm(train_loader, desc=F\"Epoch n.{epoch+1} (Train)\")): # 4: for minibatch B ⊂ X do\n",
    "\n",
    "        # We need to move to the GPU otherwise PyTorch will give issues when adding noise_batch to images\n",
    "        images = images.to(device=device)\n",
    "        labels = labels.to(device=device)\n",
    "\n",
    "        for j in range(m): # 5: for i = 1 . . . m do\n",
    "\n",
    "            # We want our model to not be trained on simple images but on images with noise δ (delta)\n",
    "            noise_batch = delta[0:images.size(0)].to(device=device).requires_grad_(True)\n",
    "            images += noise_batch\n",
    "            images.clamp_(0, 1.0)\n",
    "            images.sub_(mean).div_(std)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward(retain_graph=True) # 7: gθ ← E(x,y)∈B[∇θ l(x + δ, y, θ)] + 9: θ ← θ − τgθ ----> Plus we go popolate the noise_batch.grad value\n",
    "\n",
    "            gadv = noise_batch.grad # 8: gadv ← ∇x l(x + δ, y, θ)] ---> We already computed this, we are just storing it in a variable\n",
    "\n",
    "            # Update the noise for the next iteration\n",
    "            delta[0:images.size(0)] = delta[0:images.size(0)] + (epsilon * torch.sign(gadv)) # 11: δ ← δ + eps · sign(gadv)\n",
    "            \n",
    "            delta[0:images.size(0)] = torch.clamp_(delta[0:images.size(0)], - epsilon, epsilon) # 12: δ ← clip(δ, -eps, eps)\n",
    "\n",
    "            optimizer.step()\n",
    "            \n",
    "            # For testing\n",
    "            if epoch == 0 and j == 0:\n",
    "                imagesNorm = images\n",
    "                imagesPert = images + (epsilon * torch.sign(gadv))\n",
    "                \n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            accuracy = correct / len(labels)\n",
    "\n",
    "    # Test the model\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        mean = torch.Tensor(np.array([0.1307])[:, np.newaxis, np.newaxis])\n",
    "        mean = mean.expand(1, 28, 28).cuda()\n",
    "        std = torch.Tensor(np.array([0.3081])[:, np.newaxis, np.newaxis])\n",
    "        std = std.expand(1, 28, 28).cuda()\n",
    "\n",
    "        for images, labels in tqdm(test_loader, desc=F\"Epoch n.{epoch+1} (Validation)\"):\n",
    "            \n",
    "            images = images.to(device=device)\n",
    "            labels = labels.to(device=device)\n",
    "            \n",
    "            # compute output\n",
    "            images.sub_(mean).div_(std)\n",
    "\n",
    "            outputs = model(images)\n",
    "\n",
    "            lossVal = criterion(outputs, labels)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    # Print the loss and accuracy every 10 epochs\n",
    "    print(f'Epoch {epoch+1:03}:')     \n",
    "    print(f'\\t- Training accuracy   : {accuracy:.4f}')\n",
    "    print(f'\\t- Training loss       : {loss.item():.4f}')\n",
    "    print(f'\\t- Validation accuracy : {correct / total:.4f}')\n",
    "    print(f'\\t- Validation loss : {lossVal.item():.4f}')\n",
    "    print(\"=========================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12138b155a0>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "images1 = images + (epsilon * torch.sign(gadv))\n",
    "\n",
    "pp = np.array(images1[21].detach().cpu(), dtype='float')\n",
    "\n",
    "plt.imshow(pp.reshape(28,28,1), cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b9082d386f54bb1e876ee3493f63c8c72bc999c530e6e747cfb25eee0b2b7eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
