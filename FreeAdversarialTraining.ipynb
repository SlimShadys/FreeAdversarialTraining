{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Neural Networks__\n",
    "## Exam Project: Adversarial Training for Free!\n",
    "\n",
    "**Students**:\n",
    "- **Name**: *Gianmarco Scarano* | Matricola Code: *2047315*<br>\n",
    "- **Name**: *Giancarlo Tedesco* | Matricola Code: *2057231*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Colab compatibility\n",
    "Run this next cell only if you're using Google Colab!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library needed for this notebook\n",
    "!pip install -U tqdm --quiet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We set the global variable for Google Colab, so we can assign possible paths, etc. accordingly\n",
    "try:\n",
    "  import google.colab\n",
    "  RunningInCOLAB = True\n",
    "except:\n",
    "  RunningInCOLAB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependecies loaded\n",
      "===================================================\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "print('Dependecies loaded')\n",
    "print(\"===================================================\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if we have CUDA support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available: True\n",
      "GPU: NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "Total memory: 6.0 GB\n",
      "===================================================\n"
     ]
    }
   ],
   "source": [
    "if(torch.cuda.is_available()):\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('Cuda available: {}'.format(torch.cuda.is_available()))\n",
    "    print(\"GPU: \" + torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "    print(\"Total memory: {:.1f} GB\".format((float(torch.cuda.get_device_properties(0).total_memory / (1024 ** 3)))))\n",
    "    print(\"===================================================\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('Cuda not available, so using CPU. Please consider switching to a GPU runtime before running the notebook!')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the train dataset\n",
    "train_dataset = datasets.FashionMNIST(root ='./', train=True, download=True, transform=transform)\n",
    "\n",
    "# Download the test dataset\n",
    "test_dataset = datasets.FashionMNIST(root ='./', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create train and test data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition: DummyNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(DummyNet, self).__init__()\n",
    "\n",
    "        # First convolution\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Second convolution\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Third convolution\n",
    "        self.conv3 = nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Activation functions\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "        # Flatten layer\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(288, 150) # 288 is the output shape of the Flatten() function applied after the 3rd convolutional block.\n",
    "        self.fc2 = nn.Linear(150, 50)\n",
    "        self.fc3 = nn.Linear(50, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.relu(self.bn1(self.conv1(x)))) # First convolution\n",
    "        x = self.pool2(self.relu(self.bn2(self.conv2(x)))) # Second convolution\n",
    "        x = self.pool3(self.relu(self.bn3(self.conv3(x)))) # Third convolution\n",
    "\n",
    "        x = self.flatten(x) # Flatten of the output of the 3rd convolutional block\n",
    "\n",
    "        x = self.relu(self.fc1(x))  # FC1\n",
    "        x = self.relu(self.fc2(x))  # FC2\n",
    "\n",
    "        x = self.fc3(x)             # Output layer\n",
    "        return self.softmax(x)      # Final activation function (SoftMax)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define some variables for the training phase\n",
    "lr = 1e-3\n",
    "momentum = 0.9\n",
    "epochs = 100\n",
    "\n",
    "# Our model\n",
    "model = DummyNet(num_classes=10)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "#optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    for i, (images, labels) in enumerate(tqdm(train_loader, desc=F\"Epoch n.{epoch+1} (Train)\")):\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct = (predicted == labels).sum().item()\n",
    "        accuracy = correct / len(labels)\n",
    "\n",
    "    # Test the model\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in tqdm(test_loader, desc=F\"Epoch n.{epoch+1} (Validation)\"):\n",
    "            outputs = model(images)\n",
    "            lossVal = criterion(outputs, labels)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    # Print the loss and accuracy every 10 epochs\n",
    "    print(f'Epoch {epoch+1:03}:')     \n",
    "    print(f'\\t- Training accuracy   : {accuracy:.4f}')\n",
    "    print(f'\\t- Training loss       : {loss.item():.4f}')\n",
    "    print(f'\\t- Validation accuracy : {correct / total:.4f}')\n",
    "    print(f'\\t- Validation loss : {lossVal.item():.4f}')\n",
    "    print(\"=========================================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e4bb13fd36cd75b5c6ebf5eeb3311ccbdd31a53d4d7c1927fb46ca30d24ab112"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
